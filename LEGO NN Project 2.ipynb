{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Project 2\n",
    "## LEGO Kaggle Dataset\n",
    "\n",
    "Dominic Allard\n",
    "\n",
    "Samuel Hartle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "The dataset we are using was found on kaggle where other people can try their own hand at classifying the dataset with NN's of their own. Given some difficulties we encountered with getting the labels from the titles of the images, we followed the preprocessing steps of Guillaume Karklins who kindly provided his approach to extracting the image labels from the .png file title and process the data to allow it to work with tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and display one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "(400, 400, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define file path\n",
    "# Sam you've just gotta change the directory for all the preprocessing to use your local dataset\n",
    "#path = r\"C:\\INSERT PATH HERE\\Classifying-Lego-Brick-Images\\dataset\"\n",
    "\n",
    "# This is my file path\n",
    "path = r\"C:\\Users\\allar\\Documents\\Neural Networks\\Project 2\\Classifying-Lego-Brick-Images\\dataset\"\n",
    "\n",
    "# Load as display an image\n",
    "first = mpl.image.imread(path + \"\\\\2357 brick corner 1x2x2 000L.png\")\n",
    "print(first.dtype)\n",
    "print(first.shape)\n",
    "plt.imshow(first)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract the file names from the titles of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1)\n",
      "                                         0\n",
      "0      14719 flat tile corner 2x2 000L.png\n",
      "1      14719 flat tile corner 2x2 000R.png\n",
      "2      14719 flat tile corner 2x2 001L.png\n",
      "3      14719 flat tile corner 2x2 001R.png\n",
      "4      14719 flat tile corner 2x2 002L.png\n",
      "...                                    ...\n",
      "39995  99301 roof tile inside 3x3 397R.png\n",
      "39996  99301 roof tile inside 3x3 398L.png\n",
      "39997  99301 roof tile inside 3x3 398R.png\n",
      "39998  99301 roof tile inside 3x3 399L.png\n",
      "39999  99301 roof tile inside 3x3 399R.png\n",
      "\n",
      "[40000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract file names\n",
    "def load_names(directory):\n",
    "    f = []\n",
    "    for (filenames) in os.walk(directory):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    return f\n",
    "data = pd.DataFrame(load_names(path) [2])\n",
    "\n",
    "# Let's check:\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done, let's make a table with all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n",
      "    piece_id\n",
      "0      14719\n",
      "1      15672\n",
      "2      18654\n",
      "3       2357\n",
      "4       2420\n",
      "5       2780\n",
      "6      27925\n",
      "7       3001\n",
      "8       3002\n",
      "9       3003\n",
      "10      3004\n",
      "11      3005\n",
      "12      3010\n",
      "13      3020\n",
      "14      3021\n",
      "15      3022\n",
      "16      3023\n",
      "17      3024\n",
      "18      3037\n",
      "19      3038\n",
      "20      3039\n",
      "21      3040\n",
      "22      3045\n",
      "23      3046\n",
      "24      3062\n",
      "25      3063\n",
      "26      3068\n",
      "27      3069\n",
      "28      3070\n",
      "29      3298\n",
      "30     33909\n",
      "31      3622\n",
      "32      3623\n",
      "33      3659\n",
      "34      3675\n",
      "35      3700\n",
      "36      3794\n",
      "37      4150\n",
      "38     41677\n",
      "39     41678\n",
      "40      4274\n",
      "41      4286\n",
      "42     43093\n",
      "43     43857\n",
      "44      4490\n",
      "45     54200\n",
      "46      6143\n",
      "47      6632\n",
      "48     85984\n",
      "49     99301\n"
     ]
    }
   ],
   "source": [
    "# Make a table for all the labels\n",
    "# Rename the first column for clarity\n",
    "data.rename(columns = {0:\"file_name\"}, inplace=True)\n",
    "# Extract the piece id at the beginning of the filename\n",
    "data[\"piece_id\"] = data[\"file_name\"].str.split(\" \").str[0]\n",
    "# Drop the filename before drop duplicates\n",
    "data = data.drop([\"file_name\"], axis=1)\n",
    "# Drop duplicates\n",
    "data = data.drop_duplicates()\n",
    "# Reset ids\n",
    "data = data.reset_index(drop=True)\n",
    "# We convert the string id to numeric id\n",
    "data[\"piece_id\"] = pd.to_numeric(data[\"piece_id\"])\n",
    "\n",
    "# Let's check the size\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table done. Make a dictionary of the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Set a dictionary\n",
    "# Dictionary of piece_id's with the order id that will be used in the classifier\n",
    "dic = data.to_dict(\"dict\")[\"piece_id\"]\n",
    "\n",
    "# Set two useful id vectors\n",
    "conversion_vector = [i for i in range(len(dic))]\n",
    "print(conversion_vector)\n",
    "conversion_empty = [0 for i in range(len(dic))]\n",
    "print(conversion_empty)\n",
    "\n",
    "# General variables\n",
    "CLASS_NAMES = data[\"piece_id\"]\n",
    "NB_CLASSES = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to randomly suffle the images. Setting a random seed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files in and shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\41677 lever 2M 116L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\3037 roof tile 1x4 369L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\3675 roof tile outside 3x3 357L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\41677 lever 2M 239L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\3063 Curved Brick 2 Knobs 199R.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\41677 lever 2M 116L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\3037 roof tile 1x4 369L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\3675 roof tile outside 3x3 357L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\41677 lever 2M 239L.png'\n",
      "b'C:\\\\Users\\\\allar\\\\Documents\\\\Neural Networks\\\\Project 2\\\\Classifying-Lego-Brick-Images\\\\dataset\\\\3063 Curved Brick 2 Knobs 199R.png'\n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "# Load file names, all in the dataset directory, we remove auto shuffle\n",
    "list_ds = tf.data.Dataset.list_files(str(path + '*'), shuffle=False)\n",
    "\n",
    "# We shuffle the list, but not at each iteration because as we don't want train, test and validation datasets to overlap on a new run\n",
    "list_ds = list_ds.shuffle(40000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "# We check 2x list_ds is always shuffled in the same order\n",
    "for i in list_ds.take(5):\n",
    "    print(i.numpy())\n",
    "for i in list_ds.take(5):\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test/val split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(32000, shape=(), dtype=int64)\n",
      "tf.Tensor(4800, shape=(), dtype=int64)\n",
      "tf.Tensor(3201, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Train, test, validation split\n",
    "# Split\n",
    "train_size = int(32000)\n",
    "val_size = int(3200)\n",
    "test_size = int(4800)\n",
    "\n",
    "train_ds = list_ds.take(train_size)\n",
    "test_ds = list_ds.skip(train_size)\n",
    "val_ds = test_ds.skip(test_size)\n",
    "test_ds = test_ds.take(test_size)\n",
    "\n",
    "# Check dataset size\n",
    "print(tf.data.experimental.cardinality(train_ds))\n",
    "print(tf.data.experimental.cardinality(test_ds))\n",
    "print(tf.data.experimental.cardinality(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a bit more preprocessing so that we can feed the data into the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resize images to tensor with floats in the [0,1] range, at a specific size for the CNN\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize(img, [224, 224])\n",
    "\n",
    "# Get the label corresponding to the image returning a number in the [0,50] range , corresponding to the id in the earlier DataFrame\n",
    "def get_label(file_path):\n",
    "    parts=tf.strings.split(file_path, os.path.sep)[-1]\n",
    "    parts=tf.strings.split(parts, \" \")[0]\n",
    "    parts=tf.strings.to_number(parts, out_type=tf.dtypes.int64) \n",
    "    parts=tf.where(parts==CLASS_NAMES, conversion_vector, conversion_empty)\n",
    "    return tf.math.reduce_sum(parts)\n",
    "\n",
    "# Return Images and their corresponding label (id)\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  38\n",
      "Image shape:  (224, 224, 3)\n",
      "Label:  18\n",
      "Image shape:  (224, 224, 3)\n",
      "Label:  34\n",
      "Image shape:  (224, 224, 3)\n",
      "Label:  38\n",
      "Image shape:  (224, 224, 3)\n",
      "Label:  25\n"
     ]
    }
   ],
   "source": [
    "# Create Loading using parallel calls, hyperparameters haven't been tweaked\n",
    "train_load = train_ds.map(process_path, num_parallel_calls=1)\n",
    "test_load = test_ds.map(process_path, num_parallel_calls=1)\n",
    "val_load = val_ds.map(process_path, num_parallel_calls=1)\n",
    "\n",
    "# Check 5 images in the train dataset\n",
    "for image, label in train_load.take(5):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data again and prepare it for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache parameter was originally set on True\n",
    "def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size, reshuffle_each_iteration=True)\n",
    "    # Repeat forever after shuffling at each iteration, as the sets are now clearly distinct to have different batches at each epoch\n",
    "    ds = ds.repeat()\n",
    "  \n",
    "    # Batch by 8, this was the highest value possible with my GPU/CPU\n",
    "    ds = ds.batch(1)\n",
    "  \n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model is training. \n",
    "    # Buffer size is an hyperparameter that hasn't been tweaked, set to 1.\n",
    "    ds = ds.prefetch(buffer_size=1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our train, test, and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = prepare_for_training(train_load)\n",
    "val_set = prepare_for_training(val_load)\n",
    "test_set = prepare_for_training(test_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a Benchmark Run\n",
    "\n",
    "To get an idea on how well the NN we will develop and test in this project will perform, we'll first set up a benchmark run using our LeNet-5 NN used in the previous homework assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNET-5 Class\n",
    "class LeNet5:\n",
    "    # create the architecture\n",
    "    def build(height, width, depth, classes):\n",
    "        # create a feedforward neural net\n",
    "        model = Sequential()\n",
    "        \n",
    "        # first layer is a convolutional layer with 6 5x5 filters that have a stride of 1\n",
    "        model.add(Conv2D(filters = 6, kernel_size = (5, 5), padding = 'same', strides = 1, \n",
    "                         activation = 'tanh', input_shape = (height, width, depth)))\n",
    "        \n",
    "        # second layer is a average pooling layer with filter size 2x2 and a stride of 2\n",
    "        model.add(AveragePooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "        \n",
    "        # third layer is another convolutionl layers with 16 5x5 filters and a stride of 1\n",
    "        model.add(Conv2D(filters = 16, kernel_size = (5, 5), padding = 'same', strides = 1,\n",
    "                        activation = 'tanh'))\n",
    "        \n",
    "        # fourth layer is another average pooling layer with 2x2 filter size and stride of 2\n",
    "        model.add(AveragePooling2D(pool_size = (2, 2), strides = 2))\n",
    "        \n",
    "        # fifth layer is a fully connected convolutional layer with 120 feature maps each of size 1x1\n",
    "        model.add(Conv2D(filters = 120, kernel_size = (1, 1), padding = 'same', strides = 1,\n",
    "                        activation = 'tanh'))\n",
    "        \n",
    "        # sixth layer is a fully connected layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units = 84, activation = 'tanh'))\n",
    "        \n",
    "        # output layer is a softmax activation with 10 ouputs\n",
    "        model.add(Dense(units = classes, activation = 'softmax'))\n",
    "         \n",
    "        # return the constructed model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[5,5,6,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Mul] name: conv2d_1/kernel/Initializer/random_uniform/mul/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-afcd639b8e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Running LeNet5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeNet5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training network...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-674a37168020>\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(height, width, depth, classes)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# third layer is another convolutionl layers with 16 5x5 filters and a stride of 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         model.add(Conv2D(filters = 16, kernel_size = (5, 5), padding = 'same', strides = 1,\n\u001b[1;32m---> 17\u001b[1;33m                         activation = 'tanh'))\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# fourth layer is another average pooling layer with 2x2 filter size and stride of 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2114\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2116\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2117\u001b[0m       \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m       \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         dtype=self.dtype)\n\u001b[0m\u001b[0;32m    159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         caching_device=caching_device)\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m                         shape=None):\n\u001b[0;32m    196\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2594\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2596\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m   2597\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     return variables.RefVariable(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1409\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1540\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1542\u001b[1;33m                 \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1543\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[0;32m   1544\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[0;32m    121\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m       \u001b[0minit_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    786\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m     return op(\n\u001b[1;32m--> 788\u001b[1;33m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[1;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1199\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6120\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow compat\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,5,6,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Mul] name: conv2d_1/kernel/Initializer/random_uniform/mul/"
     ]
    }
   ],
   "source": [
    "# Running LeNet5\n",
    "model = LeNet5.build(224, 224, 3, 50)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(train_set, steps_per_epoch = int(32000/8), validation_data = val_set, validation_steps = int(3200/8),\n",
    "              epochs = 5, verbose = 1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
